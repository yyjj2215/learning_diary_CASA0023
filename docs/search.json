[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning Diary for CASA0023",
    "section": "",
    "text": "Welcome\nHello!\nWelcome to my learning diary!"
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "1  Week1 Getting started with remote sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\n\n1.1.1 what is remote sensing?\nRemote sensing is the process of detecting and monitoring the physical characteristics of an area by measuring its reflected and emitted radiation at a distance (typically from satellite or aircraft). It has two types, one is active remote sensing,the other one is passive remote sensing. The difference between them is active remote sensing has a energy source.\n\n\n\n\n\nDifferences between passive and active remote sensing. Source: Fernanda Lopez Ornelas\n\n\n\n\n\n\n1.1.2 Electromagentic waves\npropagate through space and carry momentum and electromagnetic radiant energy.\n\n\n\n\n\nElectromagentice waves. Source: Encyclopaedia Britannica\n\n\n\n\n\n\n1.1.3 Interactions with atmosphere and earth’s surface\n\n\n\n\n\n\n\n\n\nAtmosphere\nEarth’s suface\n\n\n\n\nInteraction\nscattered by particles\n\nabsorbed by the surface\ntransmitted through the surface\n\n\n\n\nScattering has three types:\na) Raleigh and Mie\n\n\n\n\n\nSource: physicsOpenLab\n\n\n\n\nb) non-selective\n\n\n\n\n\nSource: Natural Resources Canada\n\n\n\n\nRaleigh scattering(Why sky is blue? and sunset is red?)\nBlue light is scattered more than red light so the sky appears blue. The light has to travel further through the Earth’s atmosphere in sunset. The blue light is scattered away, but the red light isn’t scattered very much – so the sky appears red.\n\n\n1.1.4 Four resolutions of remote sensing data\n\n\n\n\n\n\n\n\nResolution Types\nDescription\nExamples\n\n\n\n\nspatial resolution\nthe size of the raster grid per pixel\n20cm or 30m\n\n\nspectral resolution\nthe number of bands\nBand 2 - blue (0.45-0.51 wavelength)\n\n\ntemporal resolution\nthe time it revisits\ndaily or every 7 days\n\n\nRadiometric resolution\nthe range of possible values\n8 bit, 12 bit, or 16 bit\n\n\n\n\n\n1.1.5 Raster data acquisition\nThere are many sources that provide raster data, for example, raster data can be produced by aerial photography and satellites. The common satellites data can be downloaded in two websites:\nSentinel data\nThe data is provided by the Copernicus Space Component Data Access (CSCDA), which is operating by the European Space Agency. The data has high level information, free, full, and open for all international users.\nData download link: https://scihub.copernicus.eu/dhus/#/home\nLandsat data All Landsat data are provided by the U.S. Geological Survey, and it’s also free. It has the longest free temporal data, which is useful for doing raster data analysis in temporal aspects.\nData download link: https://earthexplorer.usgs.gov/\n\n\n1.1.6 Analysis tool\nSNAP (Sentinels Application Platform) is a raster data analysis tool, and it is designed for Sentinels data. It also can manipulate Landsat data, so it has strong analysis functions. For example, resampling data, reporjecting, masking, and so on.\n\n\n\n\n\nSNAP layout Source: Yanbo 2023"
  },
  {
    "objectID": "week1.html#application",
    "href": "week1.html#application",
    "title": "1  Week1 Getting started with remote sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nColor composites are an essential concept in remote sensing. True color composites sometimes refer to the color we recognize in life. For example, the tree canopy is green, and the strawberry is red. The false color composites are to display the real color in other colors. For example, the tree canopy can be displayed as red, and the strawberry can be displayed as green. The false color composites are widely applied in many remote sensing researches.\nOne research was conducted in Afghanistan by U.S. Agency for International Development and the U.S. Trade and Development Agency, and it assessed the natural resources of Afghanistan. The following picture is a true color composite. It’s difficult to recognize some of the characteristics in this area., but the False color composite better displays individual strata, allows regional correlations of strata, and better depicts structure, such as anticlines, synclines, and faults(Philip A. (2007)).\n\n\n\n\n\nSource: Davis, P. A. 2007\n\n\n\n\n\n\n\n\n\nSource: Davis, P. A. 2007\n\n\n\n\nThe color gun can produce a variety of false color composites. And the second research compares the different combinations of false colors in Pail/Padhrar Area in Punjab Province, Pakistan (Bajwa, Ahsan, and Ahmad (2020)) The table shows the same geological formation can be displayed in various colors in different false color composites. This would be applied to many remote sensing data if we try to identify some specific features.\n\n\n\n\n\nSource: Bajwa et al. 2020"
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Week1 Getting started with remote sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nRaster data acquisition\nThe two main raster data acquisition ways are useful for future research, and I can find all raster data all over the world from Sentinel and Landsat. This actually inspires me that I can applied raster data in my final work of GEOG0114 course last term. My original topic is to explore how the thermal inequality affect people’s health in Chicago, but I don’t know where to download raster data and how to manipulate it. Then, I just gave up this topic and selected a new topic, which was doing criminology research. However, I think I’m currently able to analysis raster data in my study by using SNAP, QGIS, and R.\n\n\n\n\n\nResample and mask for Sentinel and Landsat data of Cape Town in south Africa Source: Yanbo\n\n\n\n\nSpectral signature\nI think this content will be useful for me to better understand the applications of remote sensing data. Spectral signature is the variations of reflectance and absorption for different materials in various wavelengths.\n\n\n\n\n\nTypical spectral signatures of specic land cover type Source: Anna 2017\n\n\n\n\nThe above figure provides a very good example for explanation. I can easily identify different material based on their characteristics of reflectance. For example, when the wavelengths greater than 700nm, the reflectance of green vegetation increases from 10% to 50%, this is also called red edge. This is really essential for identify green vegetation in real application and distinguish different vegetation type because the amount of Chlorophyll are various in different species. In addition, I also can use spectral signature to identify different type of materials, like explore where is the urban area, agriculture, bare land, and so on.\nColor composites\nThis concept is very interesting because I think many people have cognition that tree leaves are green, and flower is colorful. Also, in our phone, they are also displayed as the same color that we recognize in life. If they are displayed into different colors, it comes very interesting things. For example, I can use false color composites to create image has purple or pink leaves if I want. In addition, false composites are essential for remote sensing data because they can show more characteristics in the image compared to true color composites. This has been discussed in the application part, and I think I also can apply false color composites in my future study.\n\n\n\n\nBajwa, Rizwan Saqib, Naveed Ahsan, and Sajid Rashid Ahmad. 2020. “A Review of Landsat False Color Composite Images for Lithological Mapping of Pre-Cambrian to Recent Rocks: A Case Study of Pail/Padhrar Area in Punjab Province, Pakistan.” Journal of the Indian Society of Remote Sensing 48 (5): 721–28. https://doi.org/10.1007/s12524-019-01090-7.\n\n\nPhilip A., Davis. 2007. “Landsat ETM+ False-Color Image Mosaics of Afghanistan.”"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created for learning CASA0023 Remotely Sensing Cities and Environments, and it was written as a learning diary.\nI would like to thank Dr Andrew MacLachlan for helping with this book."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Week2 Portfolio",
    "section": "",
    "text": "This is my week2 presentation. Please visit link: https://yyjj2215.github.io/week2_Xaringan/."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "9  Summary",
    "section": "",
    "text": "In summary, this book"
  },
  {
    "objectID": "week1.html#what-is-remote-sensing",
    "href": "week1.html#what-is-remote-sensing",
    "title": "2  Week1 Getting started with remote sensing",
    "section": "2.2 what is remote sensing?",
    "text": "2.2 what is remote sensing?\nRemote sensing is the process of detecting and monitoring the physical characteristics of an area by measuring its reflected and emitted radiation at a distance (typically from satellite or aircraft). It has two types, one is active remote sensing,the other one is passive remote sensing. The difference between them is active remote sensing has a energy source.\n\n\n\n[Differences between passive and active remote sensing](https://www.researchgate.net/publication/339726853_The_Mexican_Water_Forest_benefits_of_using_remote_sensing_techniques_to_assess_changes_in_land_use_and_land_cover)"
  },
  {
    "objectID": "week1.html#electromagentic-waves",
    "href": "week1.html#electromagentic-waves",
    "title": "2  Week1 Getting started with remote sensing",
    "section": "2.3 Electromagentic waves",
    "text": "2.3 Electromagentic waves\npropagate through space and carry momentum and electromagnetic radiant energy.\n\n\n\n[Electromagentice waves](https://www.britannica.com/science/electromagnetic-spectrum)"
  },
  {
    "objectID": "week1.html#interactions-with-atmosphere-and-earths-surface",
    "href": "week1.html#interactions-with-atmosphere-and-earths-surface",
    "title": "2  Week1 Getting started with remote sensing",
    "section": "2.4 Interactions with atmosphere and earth’s surface",
    "text": "2.4 Interactions with atmosphere and earth’s surface\n\n\n\n\n\n\n\n\n\nAtmosphere\nEarth’s suface\n\n\n\n\nInteraction\nscattered by particles\n\nabsorbed by the surface\ntransmitted through the surface\n\n\n\n\nScattering has three types:\n\n\n\n\n\nRaleigh scattering(Why sky is blue? and sunset is red?)\nBlue light is scattered more than red light so the sky appears blue. The light has to travel further through the Earth’s atmosphere in sunset. The blue light is scattered away, but the red light isn’t scattered very much – so the sky appears red."
  },
  {
    "objectID": "week1.html#four-resolutions-of-remote-sensing-data",
    "href": "week1.html#four-resolutions-of-remote-sensing-data",
    "title": "2  Week1 Getting started with remote sensing",
    "section": "2.5 Four resolutions of remote sensing data",
    "text": "2.5 Four resolutions of remote sensing data\n\n\n\n\n\n\n\n\nResolution Types\nDescription\nExamples\n\n\n\n\nspatial resolution\nthe size of the raster grid per pixel\n20cm or 30m\n\n\nspectral resolution\nthe number of bands\nBand 2 - blue (0.45-0.51 wavelength)\n\n\ntemporal resolution\nthe time it revisits\ndaily or every 7 days\n\n\nRadiometric resolution\nthe range of possible values\n8 bit, 12 bit, or 16 bit"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bajwa, Rizwan Saqib, Naveed Ahsan, and Sajid Rashid Ahmad. 2020.\n“A Review of Landsat False Color Composite Images for Lithological\nMapping of Pre-Cambrian to Recent Rocks: A Case Study of Pail/Padhrar\nArea in Punjab Province, Pakistan.” Journal of the Indian\nSociety of Remote Sensing 48 (5): 721–28. https://doi.org/10.1007/s12524-019-01090-7.\n\n\nErmida, Sofia L., Patrícia Soares, Vasco Mantas, Frank-M. Göttsche, and\nIsabel F. Trigo. 2020. “Google Earth Engine Open-Source Code for\nLand Surface Temperature Estimation from the Landsat Series.”\nRemote Sensing 12 (9): 1471. https://doi.org/10.3390/rs12091471.\n\n\nLocke, Dexter H., J. Morgan Grove, Jacqueline W. T. Lu, Austin Troy,\nJarlath P. M. O’Niel-Dunne, and Brian D. Beck. 2010. “Prioritizing\nPreferable Locations for Increasing Urban Tree Canopy in New York\nCity.” Cities and the Environment 3 (1): 1–18. https://doi.org/10.15365/cate.3142010.\n\n\nLoukika, Kotapati Narayana, Venkata Reddy Keesara, and Venkataramana\nSridhar. 2021a. “Analysis of Land Use and Land Cover Using Machine\nLearning Algorithms on Google Earth Engine for Munneru River Basin,\nIndia.” Sustainability 13 (24): 13758. https://doi.org/10.3390/su132413758.\n\n\n———. 2021b. “Analysis of Land Use and Land Cover Using Machine\nLearning Algorithms on Google Earth Engine for Munneru River Basin,\nIndia.” Sustainability 13 (24): 13758. https://doi.org/10.3390/su132413758.\n\n\nMoravec, David, Jan Komárek, Serafín López-Cuervo Medina, and Iñigo\nMolina. 2021. “Effect of Atmospheric Corrections on NDVI:\nIntercomparability of Landsat 8, Sentinel-2, and UAV Sensors.”\nRemote Sensing 13 (18): 3550. https://doi.org/10.3390/rs13183550.\n\n\nPhan, Thanh Noi, Verena Kuch, and Lukas W. Lehnert. 2020. “Land\nCover Classification Using Google Earth Engine and Random Forest\nClassifierThe Role of Image Composition.” Remote\nSensing 12 (15): 2411. https://doi.org/10.3390/rs12152411.\n\n\nPhilip A., Davis. 2007. “Landsat ETM+ False-Color Image Mosaics of\nAfghanistan.”\n\n\nPoncet, Aurelie M., Thorsten Knappenberger, Christian Brodbeck, Michael\nFogle, Joey N. Shaw, and Brenda V. Ortiz. 2019a. “Multispectral\nUAS Data Accuracy for Different Radiometric Calibration Methods.”\nRemote Sensing 11 (16): 1917. https://doi.org/10.3390/rs11161917.\n\n\n———. 2019b. “Multispectral UAS Data Accuracy for Different\nRadiometric Calibration Methods.” Remote Sensing 11\n(16): 1917. https://doi.org/10.3390/rs11161917.\n\n\nSidhu, Nanki, Edzer Pebesma, and Gilberto Câmara. 2018a. “Using\nGoogle Earth Engine to Detect Land Cover Change: Singapore as a Use\nCase.” European Journal of Remote Sensing 51 (1):\n486–500. https://doi.org/10.1080/22797254.2018.1451782.\n\n\n———. 2018b. “Using Google Earth Engine to Detect Land Cover\nChange: Singapore as a Use Case.” European Journal of Remote\nSensing 51 (1): 486–500. https://doi.org/10.1080/22797254.2018.1451782.\n\n\n———. 2018c. “Using Google Earth Engine to Detect Land Cover\nChange: Singapore as a Use Case.” European Journal of Remote\nSensing 51 (1): 486–500. https://doi.org/10.1080/22797254.2018.1451782.\n\n\nWu, Chunxia, Qingfu Xiao, and E. Gregory McPherson. 2008. “A\nMethod for Locating Potential Tree-Planting Sites in Urban Areas: A Case\nStudy of Los Angeles, USA.” Urban Forestry & Urban\nGreening 7 (2): 65–76. https://doi.org/10.1016/j.ufug.2008.01.002."
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "3  Week3 Remote sensing data",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\n3.1.1 How Landsat obtain image data by using scanners?\nThe remote sensing data are collected by multispectral scanners, and they can detect different electromagnetic bands of radiation. These data are digitally processed and transmitted to ground station.\nTwo main ways of scanning and acquire image data:\n\n\n\nWhiskbroom\nPushbroom\n\n\n\n\nAcross-track scanning\nAlong-track scanning\n\n\nWide swath width\nNarrow swath width\n\n\nSimple optical system\nComplex optical system\n\n\nShorter dwell time\nLonger dwell time\n\n\nPixel distortion\nNo pixel distortion\n\n\nExample: Landsat 7\nExample: Landsat 8\n\n\n\n\n\n\n\n\nWhishbroom. Source: wikipedia\n\n\n\n\n\n\n\n\n\nPushbroom. Source: wikipedia\n\n\n\n\n\n\n3.1.2 Why remote sensing data need to be processed?\nThis may cause by some noise that are produced by sensors, the atmosphere, the terrain, and so on. For example, the atmosphere causes some noise in collecting data, like atmospheric pollution, floating particles. These noise can be removed by using some correction measures.\n\n\n3.1.3 Corrections of image data\n\n3.1.3.1 Geometric correction\nWhen collecting image data, there are some geometric errors. These images can be adjusted by using scale, orientation, and projection, which can match the spatial characteristics of earth surface.\nReasons for image distortions\n\nView angle\nTopography (like hills or not flat ground)\nWind (Using plane to collect data)\nRotation of the earth (Using satellite to collect data)\n\nSolutions for geometric correction\n\nidentify ground control points\nbuild models to provide geometric transformation coefficients\ntransform coordinates of pixels locations\n\n\n\n\n\n\nCoordinates transformation. Source: wikipedia\n\n\n\n\n\nresample pixels values\n\n\n\n\n\n\nResample pixels. Source:Studley 2011\n\n\n\n\nExample for correct a old map in GIS\n\n\n\n\n\nGeometric correction for old map. Source: Yanbo\n\n\n\n\n\n\n3.1.3.2 Atmospheric correction\nEarth’s atmosphere has water vapor and ozone and other gases, and they will have effects on the measuring process. These effects can be removed when using remote sensing data, which is atmospheric correction.\nNecessary and unnecessary atmospheric correction :\n\n\n\n\n\n\n\nUnnecessary\nNecessary\n\n\n\n\nClassification of a single image\nBiophysical parameters needed (e.g. temperature, leaf area index, NDVI)\n\n\nIndependent classification of multi date imagery\nUsing spectral signatures through time and space\n\n\nComposite images (combining images)\n\n\n\nSingle dates or where training data extracted from all data\n\n\n\n\nSource: CASA0023 slides P26\nTypes of atmospheric correction:\nRelative\nnormalize intensities of different bands within a single image and bands from many dates to one date\nAbsolute\nuse atmospheric conditions and illumination at the time of image collection, which to estimate the amount of scattering and absorption in images. Then, change digital brightness values into scaled surface reflectance. This can be done through atmospheric radiative transfer models.\n\n\n\n3.1.3.3 Orthorectification correction\nThe topography of earth has variation, like hills, ridges, canyon and so on. Also, the satellite will have tilt when they collect data. Both of them have effects on the images. Basically, various topographical features and angles of satellite causes more inherent distortion in remote sensing data.\n\n\n\n\n\nSource: Satellite Imaging Corporation\n\n\n\n\nThis is a example of orthorectification, and the left picture shows crooked road, but the right picture shows the real straight road after orthorectification.\n\n\n\n\n\nExample of before orthorectification and after Source: OSSIM\n\n\n\n\n\n\n3.1.3.4 Radiometric Calibration\nAlthough many imagery data has already been converted to radiance by data provider, the process of radiometric calibration should be noticed. It refers to conversion of digital number(DN) to spectral radiance. DN is values in every pixels, and they are observed and measured by sensors. The spectral radiance is the amount of energy per unit area, like the amount of light from sensor in the field of view. There are many factors that affects radiance. For example, the intensity of illumination, the direction of illumination, orientation, position of target feature, and so on.\n\n\n\n\n\nFactors that affect radiance Source: Susan 2020\n\n\n\n\n\n\n\n3.1.4 Mosaicking and Image enhancement\nMosaicking\nIt is similar to merge function in QGIS. For instance, some image data can be merged together based on the characteristics of each image, finally produces a new image.\n\n\n\n\n\nMosaicking Source: ArcGis\n\n\n\n\nImage enhancement\nIn order to better visualize characteristics on images, image can be enhanced by using many different methods, like stretch and spatial filtering. The following picture shows contrast is enhanced, and the visual interpretation can be easier.\n\n\n\n\n\nLinear contrast stretch Source: CCRS"
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "3  Week3 Remote sensing data",
    "section": "3.2 Application",
    "text": "3.2 Application\nExplorations of radiometric calibration methods in UAS data\nThere are many methods for radiometric calibration. Generally, when you have some remote sensing data, image producers will have some recommended methods, but there are also some empirical methods. One research had compared five common methods by using unmanned aircraft systems data, which tries to explore the best performance of radiometric calibration. The five methods are one-point calibration (method A), one-point calibration plus sunshine sensor (method B), pre-calibration using the simplified empirical line calibration (method C) , one-point calibration plus sunshine sensor plus post-calibration(method D), and post-calibration using the simplified empirical line calibration (method E). The paper found there are no method that can have the best performance in every band Poncet et al. (2019a).\n\n\n\n\n\nRMSE values in all methods Source: Aurelie et al. 2019\n\n\n\n\n\n\n\n\n\nThe distributions of RMSE values in each band Source: Aurelie et al. 2019\n\n\n\n\nThe RMSE values are various in different bands, and they should be always noticed. For example, method B has lower RMSE in red-edge and NIR, but higher in green band. So we need to select the suitable method for radiometric calibration depending on our objectives Poncet et al. (2019b). The analysis of imagery data can be more careful because the radiometric calibration method may have influence on the interpretation of UAS imagery.\nEffects of Atmospheric Corrections on NDVI\nVegetation measurement is an essential application in remote sensing, and NDVI is Normalized Difference Vegetation Index (NDVI), which can quantify vegetation health. For example, when NDVI values are close to +1, the vegetation should be dense green, and when NDVI values are close to 0, there are no green. The NDVI formula is following:\n\n\n\n\n\nNDVI formula: GISGeography\n\n\n\n\n\n\n\n\n\nNDVI values Source: GISGeography\n\n\n\n\nOne study explored common methods (QUAC, FLAASH, DOS, ACOLITE, 6S, and Sen2Cor) for atmospheric Corrections on NDVI by using Landsat 8, Sentinel-2, and UAV sensors data. In real raster data analysis, data probably are from different source, so the atmospheric correction, to some extent, make them more comparable. In this paper, FLAASH method has the best distinctiveness on NDVI between Landsat 8 and Sentinel-2. Moravec et al. (2021).\n\n\n\n\n\nMedian values of non-corrected TOA and corrected BOA Source: David 2021"
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Week3 Remote sensing data",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nImage enhancement\nIn the week 1, the false color composites can enhance the characteristics of image, and I think image enhancement also plays a similar role in visualizing image. In QGIS, there are many options for contrast enhancement, and I can set the min/max value for raster data.\n\n\n\n\n\nContrast enhancement Source: Yanbo\n\n\n\n\n\n\n\n\n\nNo enhancement vs contrast enhancement Source: Yanbo\n\n\n\n\nIn the enhancement image, I can more easily distinguish the boundary of grass and forest, so enhancement is really useful for real analysis in my study.\nMosaicking\nThis is similar to the merge function in QGIS, and merge is essential function. If my study area is not fully recorded by one raster data, I have to mosaic several raster data together in order to get my study area.\nPrincipal Component Analysis\nI think PCA would be a powerful tool in the future study. This contributes to reduce the dimensionality of data. In real remote sensing data analysis, I think the data probably have multiple dimensions, and the PCA would be functional to reduce them, which help us identify which components are more important among the data. For example, I can use PCA in exploring vegetation patterns, which tries to find what vegetation type dominate in study area.\n\n\n\n\nMoravec, David, Jan Komárek, Serafín López-Cuervo Medina, and Iñigo Molina. 2021. “Effect of Atmospheric Corrections on NDVI: Intercomparability of Landsat 8, Sentinel-2, and UAV Sensors.” Remote Sensing 13 (18): 3550. https://doi.org/10.3390/rs13183550.\n\n\nPoncet, Aurelie M., Thorsten Knappenberger, Christian Brodbeck, Michael Fogle, Joey N. Shaw, and Brenda V. Ortiz. 2019a. “Multispectral UAS Data Accuracy for Different Radiometric Calibration Methods.” Remote Sensing 11 (16): 1917. https://doi.org/10.3390/rs11161917.\n\n\n———. 2019b. “Multispectral UAS Data Accuracy for Different Radiometric Calibration Methods.” Remote Sensing 11 (16): 1917. https://doi.org/10.3390/rs11161917."
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "4  Week4 Policy",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nCity: Seattle, US\nSeattle is a vibrant and lively city on the west coast of the US. The city has 4 million people in the metropolitan area. It is one of the fastest-growing large cities, which is home to many renowned companies, including Amazon, Microsoft, Boeing, and Starbucks. Also, the city has diverse cultures, beautiful landscape, great outdoor recreation, and environmental stewardship. Therefore, it has strong cultural and job attractions for the surrounding areas. There are more than four thousand new settlers each year. This requires the city of Seattle to have a better understanding and planning of the city. \nGlobal Policy\nSustainable development goals (SGDs) were formulated in 2015 by the United Nations General Assembly (UNGA), which aims to provide a future development framework. It includes 17 goals that emphasize in the sustainability of social, environment, and economic aspects.\n\n\n\n\n\nSustainable Goals. Source: United Nations\n\n\n\n\n\n\n\n\n\nGoal 11. Source: United Nations\n\n\n\n\n\nTarget 11.7 By 2030, provide universal access to safe, inclusive and accessible, green and public spaces, in particular for women and children, older persons and persons with disabilities.\n\nMetropolitan policy\nThe city of Seattle has a comprehensive plan (2015-2035) in order to become an equitable and sustainable city. The core values of Seattle include, race and social equality, environmental stewardship, community, economic opportunity and security.\n\n\n\n\n\nSeattle 2035. Source: City of Seattle\n\n\n\n\nGoal\n\nENG1: Foster healthy trees, vegetation, and soils to improve human health, provide wildlife habitats, improve drainage, give residents across the city access to nature, provide fresh food, and increase the quality of life for all Seattleites.\n\nPolicies\n\nEN 1.1: Seek to achieve an urban forest that contains a thriving and sustainable mix of tree species and ages, and that creates a contiguous and healthy ecosystem that is valued and cared for by the City and all Seattleites as an essential environmental, economic, and community asset.\n\n\nEN 1.2: Strive to increase citywide tree canopy coverage to 30 percent by 2037 and to 40 percent over time.\n\n\nEN 1.3: Use trees, vegetation, green stormwater infrastructure, amended soil, green roofs, and other low-impact development features to meet drainage needs and reduce the impacts of development. \n\nThese three policies and goals mainly aim to improve the urban forest in Seattle. The urban forest is make up of all individual trees, street trees, green spaces with trees, and associated vegetation in the urban area. Basically, the policies and goals requires city of Seattle have a better management, interpreation, and monitoring of their urban forest.\nSeattle Policy Document"
  },
  {
    "objectID": "week4.html#metropolitan-policy-documents",
    "href": "week4.html#metropolitan-policy-documents",
    "title": "4  Week4 Policy",
    "section": "4.2 Metropolitan policy documents",
    "text": "4.2 Metropolitan policy documents\nThe city of Seattle has a comprehensive plan (2015-2035) in order to become an equitable and sustainable city. The core values of  Seattle include, race and social equality, environmental stewardship, community, economic opportunity and security. However, the goals and policies in the plan don’t provide the detailed solutions that contribute to achieve them. My proposal tries to generate some detailed solutions for environmental goals and policies, which contribute to the health and sustainability of the natural environment in Seattle.\nGoal\nENG1: Foster healthy trees, vegetation, and soils to improve human health, provide wildlife habitats, improve drainage, give residents across the city access to nature, provide fresh food, and increase the quality of life for all Seattleites.\nPolices\nEN 1.1: Seek to achieve an urban forest that contains a thriving and sustainable mix of tree species and ages, and that creates a contiguous and healthy ecosystem that is valued and cared for by the City and all Seattleites as an essential environmental, economic, and community asset. \nEN 1.2: Strive to increase citywide tree canopy coverage to 30 percent by 2037 and to 40 percent over time. \nEN 1.3: Use trees, vegetation, green stormwater infrastructure, amended soil, green roofs, and other low-impact development features to meet drainage needs and reduce the impacts of development. \nSeattle policy link: https://www.seattle.gov/Documents/Departments/OPCD/OngoingInitiatives/SeattlesComprehensivePlan/CouncilAdopted2020.pdf"
  },
  {
    "objectID": "week4.html#application",
    "href": "week4.html#application",
    "title": "4  Week4 Policy",
    "section": "4.2 Application",
    "text": "4.2 Application\nThe goals and policies in the Seattle plan don’t provide the detailed solutions that contribute to achieve them. In order to improve tree canopy cover in Seattle, I think two steps are necessary, and they should be detailed.\n\nexplore the neighborhoods with a high preferablity of planting tree\nidentify the potential planting site in areas with a high priority of tree planting\n\nIn this application, I tries to review some literature and generate some detailed solutions for increasing canopy cover and urban forest, which contribute and support to the health and sustainability of the natural environment in Seattle.\nNeighborhood level: Preferable locations analysis of urban tree planting\nThe study conducted by Locke et al. (2010) analyzed the preferable locations of urban tree planting in New York City, they narrowed the preferable locations to the neighborhood levels. Although the data they used is not remote sensing data, the method of identifying the preferable locations of urban trees are also useful for Seattle. They used need-based criteria for preferability analysis. For example, when some neighborhood with a higher temperature in summer, it would be a high priority area for planting a tree.\n\n\n\n\n\nExamples of variables in preferablity analysis. Source: Locke et al., 2010\n\n\n\n\nThey combined many variables together, and assigned the different weights based on the importance of variables. Finally, they produced a map that shows neighborhoods with different priority for planting trees.\n\n\n\n\n\nPrioritization map of planting trees. Source: Locke et al., 2010\n\n\n\n\nIndividual tree level: the potential planting sites analysis\nThis study conducted by Wu, Xiao, and McPherson (2008) developed a computer program, which virtually planted three types of trees(small, medium, and large trees) in Los Angeles by using satellite data. It can iterativelly find the potential planting areas, and this would be really useful for planting department in every city. The planting department can combine the virtually planting sites with the real site conditions to plant a new tree for city.\ndata\n\nsource：QuickBird satellite\nspatial resolution: 2.4m\nbands: blue, green, red, near-infrared , and a panchromatic band with 60cm\ntemporal resolution: 64 scenes collected from 2002 to 2005\n\nMethod\nThe computer program iterativelly search all the potential planting site, and it will avoid areas that are not suitable to plant trees, like sites too close to the buildings, pavings and so on.\n\n\n\n\n\nFlowchart of tree planting. Source: Wu, Xiao, and McPherson, 2008\n\n\n\n\nOutput\nThe circles are potential planted trees, and the size of circles stands for small, medium, and large trees in the neiborhood.\n\n\n\n\n\nPotential trees planted. Source: Wu, Xiao, and McPherson, 2008"
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4  Week4 Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nI think I need to always consider the policies and goals in the application of remote sensing data. The remote sensing data are not only limited in doing research, but also contributed to the development of cities. This will provide a positive loop in both remote sensing development and city development. Also, the policy about increasing green canopy is proposed by many cities, and this would be a great research direction for me. \nThe policies not only have limitations on how to achieve the policies, but also they should provide some detailed guides about tree and vegetation species for citizens. This will engage more citizens to join the planting work, and they may plant more trees in their gardens. It also can avoid some potential risks in the tree planting process. There are many invasive plants in North America, people usually have a high possibility to plant a wrong plant that causes plant invasion.\nThe two cases in the application part only considered the new planting trees. The management and monitoring of existing trees also essential for the achivment of goals and policies. For example, some LiDAR data can be used to detect the height of trees, and also monitoring the tree health. Unhealthy trees can be treated or replaced.\nThe financial part of the implementation of the solution is not considered, and it’s also important for the city of Seattle. The cost of this solution may cause by acquisition of remote sensing data, the implementation of planting trees including planting workers, the costs of nursery trees, and maintenance fees.\n\n\n\n\n\n\nLocke, Dexter H., J. Morgan Grove, Jacqueline W. T. Lu, Austin Troy, Jarlath P. M. O’Niel-Dunne, and Brian D. Beck. 2010. “Prioritizing Preferable Locations for Increasing Urban Tree Canopy in New York City.” Cities and the Environment 3 (1): 1–18. https://doi.org/10.15365/cate.3142010.\n\n\nWu, Chunxia, Qingfu Xiao, and E. Gregory McPherson. 2008. “A Method for Locating Potential Tree-Planting Sites in Urban Areas: A Case Study of Los Angeles, USA.” Urban Forestry & Urban Greening 7 (2): 65–76. https://doi.org/10.1016/j.ufug.2008.01.002."
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5  Week5 An introduction to Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\n\n5.1.1 What is Google Earth Engine?\nGoogle Earth Engine is a cloud platform developed by Google, and it can process satellite imagery from Landsat and other geospatial data uploaded by users.\nUser guide\n\n\n5.1.2 Mind map\n\n\n\n\n\nMind map. Source:Yanbo\n\n\n\n\n\n\n5.1.3 Key concepts about GEE\nGEE terms\n\n\n\nGEE\nR\n\n\n\n\nimage\nraster\n\n\nfeature\nvector\n\n\nstack\ncollection\n\n\n\nJavascript\nGEE use javascript (web programming language) to manipulate data.\n\nvar define objects\n// add comments\n\n// key codes in GEE\n\nvar number = 1 \n\nvar string = 'Hello, World!'\n\nvar list = [1.23, 8, -3]\nprint(list[2])\n\nvar dictionary = {\n  a: 'Hello',\n  b: 10,\n  c: 0.1343,\n  d: list\n}\n\nprint(dictionary.b)\nprint(number, string, list, dictionary)\nClient and server\n\n\n\nclient\nserver\n\n\n\n\nweb page on the browser\nall data are stored on the server\n\n\ncode shows on the browser\ncodes runs on the server\n\n\n\nLoop and map\n\ndon’t use loop on the server\nuse mapping functions(only loading image collection once, and get results)\ncode examples\nLoop\nlist = [1,2,3]\n\nbias = 1\n\nx = 0\n\nfor x < list.length:\n  list[x]=list[x]+bias\n\nlist= [2,3,4]\nMap\nlist.map(list=list+1)\n\nlist =[2,3,4]\n\nScale\n\nrefers to pixel resolution\noutput are aggregated (256*256 grid)\nalways need to set a scale, if not, the pixel values may change\n\n\n\n\n\n\nScale. Source: Google Developers\n\n\n\n\nProjection\ndisplays all data into Mercator projection (EPSG: 3857)\n\n\n5.1.4 How to use GEE?\nObjects and method overview\n\n\n\n\n\nCommon Earth Engine object classes. Source: Google Earth Engine\n\n\n\n\nCode editor\n\n\n\n\n\nCode editor. Source: Google Earth Engine\n\n\n\n\nLoad image collection\nuse ee.ImageCollection() to load, filterDate() and filterBounds() to select specific date and locations, otherwise, GEE will have errors because too many elements.\nvar oneimage = ee.ImageCollection('LANDSAT/LC09/C02/T1_L2')\n  .filterDate('2022-01-03', '2022-04-04')\n  .filterBounds(Dheli);  // Intersecting ROI\nMap.addLayer(oneimage, {bands: [\"SR_B4\", \"SR_B3\", \"SR_B2\"]})\nLoad feature collection\nfeatures refers to the geometries with attributes, use ee.FeatureCollection() to load, filter() to select specific area, like R\nvar india = ee.FeatureCollection('users/jesse/china');\nprint(china, \"china\");\nMap.addLayer(china, {}, \"china\");\nvar india = ee.FeatureCollection('users/jesse/china')\n    .filter('GID_1 == \"CHN.25_1\"');\nReducing images\nWhen I only want to classify one image from a massive image collections, use this method. The process of this is to take all median of all images to make a image composite, then summarized into one single image. This process ignored some extreme values, but they may be useful.\ncollection.reduce() client side\nee.Reducer() server side\n// Compute the median in each band, each pixel.\n// Band names are B1_median, B2_median, etc.\nvar median = collection.reduce(ee.Reducer.median());\nby region\nreduceRegion() reduce region a single region\nby region(s)\nreduceRegions() reduce region in many small areas\nby neighborhood\nreduceNeighborhood() reduce by image neighborhood (surrounded pixels)\nLinear regression\nlinearFit() Look change over time. For example, the change of temperature over last decades\n\ndependent variables, like temperature\nindependent varibles, often time\n\nMultiple Linear Regression\nconstant band are required, and need to mentioned the number of X and Y\n.map(createConstantBand)\nvar linearRegression = collection.reduce(\n  ee.Reducer.linearRegression({\n    numX: 2,\n    numY: 2\n}));\nJoin\njoin.apply() similar to joins in R\nExample: add all plants within 100km buffer of the National park\ncode link: https://code.earthengine.google.com/7424ebd78cf7d634f161a0a0619019ea (Source: Andrew Maclachlan)\n\n\n5.1.5 Common examples of GEE Analysis\nmy code link: https://code.earthengine.google.com/a0d4d4aa44552e6a529e39a1d6a3f572\nClip Images\nuse polygon to clip study area\nvar clip = meanImage.clip(india)\n  .select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']);\n\nvar vis_params3 = {\n  bands: ['SR_B4', 'SR_B3', 'SR_B2'],\n  min: 0,\n  max: 0.3,\n};\n\n// map the layer\nMap.addLayer(clip, vis_params3, 'clip');\n\n\n\n\n\nClip output. Source: Yanbo\n\n\n\n\nTexture measures\nhelp users to extract useful information by applying some mathematical formulas on pixels values. So it can improve the accuracy of image classification and enhance the interpretation of remote sensing data.\n\nuse glcmTexture() in GEE\nsize means the number of neighborhoods, 1 means a 3*3 grid\n\nvar glcm = clip.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7'])\n  .multiply(1000)\n  .toUint16()\n  .glcmTexture({size: 1})\n  .select('SR_.._contrast|SR_.._diss')\n  .addBands(clip);\n  \n// add to the map, but change the range values  \nMap.addLayer(glcm, {min:14, max: 650}, 'glcm');\n\n\n\n\n\nTexture measures output. Source: Yanbo\n\n\n\n\nPCA\n// scale and band names\n\nvar scale = 30;\nvar bandNames = glcm.bandNames();\nprint('GLCM band names:', glcm.bandNames());\n\nvar region = india.geometry();\nMap.centerObject(region, 10);\nMap.addLayer(ee.Image().paint(region, 0, 2), {}, 'Region');\n\nprint(region, \"india_geometry\");\n\n// mean center the data and SD strech the princapal components \n// and an SD stretch of the principal components.\nprint('bandNames:', bandNames);\nvar meanDict = glcm.reduceRegion({\n    reducer: ee.Reducer.mean(),\n    geometry: region,\n    scale: scale,\n    maxPixels: 1e9\n});\nprint('Mean Dictionary:', meanDict);\nvar means = ee.Image.constant(meanDict.values(bandNames));\nprint(\"Means: \", means);\nvar centered = glcm.subtract(means);\n\n// This helper function returns a list of new band names.\nvar getNewBandNames = function(prefix) {\n  var seq = ee.List.sequence(1, bandNames.length());\n  return seq.map(function(b) {\n    return ee.String(prefix).cat(ee.Number(b).int());\n  });\n};\n\n\n// This function accepts mean centered imagery, a scale and\n// a region in which to perform the analysis.  It returns the\n// Principal Components (PC) in the region as a new image.\nvar getPrincipalComponents = function(centered, scale, region) {\n  // Collapse the bands of the image into a 1D array per pixel.\n  var arrays = centered.toArray();\n\n  // Compute the covariance of the bands within the region.\n  var covar = arrays.reduceRegion({\n    reducer: ee.Reducer.centeredCovariance(),\n    geometry: region,\n    scale: scale,\n    maxPixels: 1e9\n  });\n\n  // Get the 'array' covariance result and cast to an array.\n  // This represents the band-to-band covariance within the region.\n  var covarArray = ee.Array(covar.get('array'));\n\n  // Perform an eigen analysis and slice apart the values and vectors.\n  var eigens = covarArray.eigen();\n\n  // This is a P-length vector of Eigenvalues.\n  var eigenValues = eigens.slice(1, 0, 1);\n  // This is a PxP matrix with eigenvectors in rows.\n  \n  var eigenValuesList = eigenValues.toList().flatten();\n  var total = eigenValuesList.reduce(ee.Reducer.sum());\n  var percentageVariance = eigenValuesList.map(function(item) {\n  return (ee.Number(item).divide(total)).multiply(100).format('%.2f')});\n  \n  print(\"percentageVariance\", percentageVariance);\n\n  var eigenVectors = eigens.slice(1, 1);\n\n  // Convert the array image to 2D arrays for matrix computations.\n  var arrayImage = arrays.toArray(1);\n\n  // Left multiply the image array by the matrix of eigenvectors.\n  var principalComponents = ee.Image(eigenVectors).matrixMultiply(arrayImage);\n\n  // Turn the square roots of the Eigenvalues into a P-band image.\n  var sdImage = ee.Image(eigenValues.sqrt())\n    .arrayProject([0]).arrayFlatten([getNewBandNames('sd')]);\n\n  // Turn the PCs into a P-band image, normalized by SD.\n  return principalComponents\n    // Throw out an an unneeded dimension, [[]] -> [].\n    .arrayProject([0])\n    // Make the one band array image a multi-band image, [] -> image.\n    .arrayFlatten([getNewBandNames('pc')])\n    // Normalize the PCs by their SDs.\n    .divide(sdImage);\n};\n\n// Get the PCs at the specified scale and in the specified region\nvar pcImage = getPrincipalComponents(centered, scale, region);\n\n\nMap.addLayer(pcImage, {bands: ['pc2', 'pc1'], min: -2, max: 2}, 'PCA bands 1 and 2');\np1 and p2 has the highest percentage, and they are the most important components. Here, extract pc1 and pc2.\n\n\n\n\n\nPCA percentage list. Source: Yanbo\n\n\n\n\n\n\n\n\n\nPCA output. Source: Yanbo\n\n\n\n\nNDVI\nimportant index that helps vegetation analysis in many cases.\n// common methods\nvar NDVI_1 = clip.select('SR_B5').subtract(clip.select('SR_B4'))\n  .divide(clip.select('SR_5').add(clip.select('SR_B4')));\n// GEE functions\nvar NDVI_2 = clip.normalizedDifference([SR_B5, SR_B4]);\nMap.addLayer(NDVI_1, { min: -1, max: 1, palette: ['blue', 'white', 'green']}, 'NDVI');\n\n\n\n\n\nNDVI output. Source: Yanbo\n\n\n\n\nExport layers\nuse Export.image.toDrive()\n// Export the image, specifying the CRS, transform, and region.\nExport.image.toDrive({\n  image: PCA_out,\n  description: 'PCA_india',\n  scale:30,\n  crs: projection.crs,\n  maxPixels: 100E10,\n  region: bounds\n\n});"
  },
  {
    "objectID": "week5.html#application",
    "href": "week5.html#application",
    "title": "5  Week5 An introduction to Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\nGoogle earth engine is a powerful tool with many advantages in remote sensing analysis. It does not require users to download large satellite images, and users can access a large range of Landsat images stored on the server. It also has a strong computing platform, and users can do analysis on the server rather than running analysis on personal computers. In this application, I tried to explore some papers, and find the procedure of remote sensing analysis in Google Earth Engine.\n\n5.2.1 Case 1: Detecting land cover change in Singapore\nThe first paper was conducted by Sidhu, Pebesma, and Câmara (2018a), and they explored the land cover change by using GEE in Singapore. Also, they examined the ability of GEE, and they found GEE has three strengths. The first one is the ease of functionality, and they can easily upload other data by using Asset Manager. Then, GEE has efficient processing capabilities, and this makes it easy to run spatial reductions. Finally, the computational powers are strong, and the computational times are within a matter of time. Moreover, they found the activity of dredging increased from 2006 to 2010 in Singapore (Sidhu, Pebesma, and Câmara (2018b)).\nMethod\nThe framework of the method they used clearly shows the analysis procedures of doing remote sensing research in GEE. In the data preparation, they uploaded some imagery and filtered imagery on GEE. Then, they used the polygon of the study area to clip the imagery. Finally, they created a function for collection reductions.\n\n\n\n\n\nMethodological framework. Source: Sidhu, Pebesma, and Câmara, 2018\n\n\n\n\nThis framework of method focuses on the analysis of remote sensing data at the temporal level. The main function applied here is reducer in GEE. However, GEE also can do analysis like PCA, and texture measure. This requires a different framework of the method.\nOutput\n\n\n\n\n\nLand cover change (2006, 2008, 2010). Source: Sidhu, Pebesma, and Câmara, 2018\n\n\n\n\n\n\n5.2.2 Case2: Land Surface Temperature Estimation in central Portugal\nThe second paper applied GEE to estimate land surface temperature(LST). LST is an important factor contributing to many scientific studies. However, the traditional way to get the LST is relatively hard for some users. This paper illustrates the detailed steps of calculating LST and the free code in GEE. Other users can easily change the dataset and create their LST data of study areas by running codes in GEE.\nThis study used Landsat 4 to Landsat 8 data and calculated the LST by Statistical Mono-Window (SMW algorithm), and this algorithm is calibrated(Ermida et al. (2020)). The detailed processing steps are followed in the next figure. The blue words shows functions and the grey words shows datasets used in analysis. Both TOA and SR collection are processed with cloudmask, and this reduces the influence of clouds in the data.\n\n\n\n\n\nGEE processing chain. Source: Ermida et. al, 2020\n\n\n\n\nOutput\nThe bottom right figure shows the final LST in study area, and the remaining figures are the data used in SMW algorithm.\n\n\n\n\n\nFinal LST. Source: Ermida et. al, 2020\n\n\n\n\nCode link: https://earthengine.googlesource.com/users/sofiaermida/landsat_smw_lst\n(Source: Ermida et. al, 2020)"
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "5  Week5 An introduction to Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nMost of the analysis for remote sensing data in GEE is easier than those in R. For example, I don’t need to download data, and load them in R or SNAP, and I can easily access the data and visualize them in GEE. Also, the texture measure in GEE is just a few codes, but it is complex in R. However, the PCA in GEE is quite more complex than it in R.\nIn practice this week, I found print() is a really useful function that can help me identify errors in the code, and it also helps me to check the result of every step in the right way. For instance, there is a wrong object used in the code, and when I applied the get_info() function, it showed there is no this band. Finally, I used print() to find where had the wrong object. In addition, the NDVI in band math will be a useful tool for identifying vegetation in the study area. Similarly, LST in the second case study is also a good variable when exploring some topics about temperature.\nThe google earth engine codes are sharable, which is similar to GitHub. This provides more chances to group work and generates a better analysis process in teamwork. Also, I can explore many open-source codes so that I can learn other data analysis processes and methods in the future.\nI think GEE is a form of big data application in the geospatial data area because it can store massive data on the server, and the users use Javascript to query and load data. The first paper mentions that GEE uses MapReduce architecture (Sidhu, Pebesma, and Câmara (2018c)), which is popular in big data technology. The idea of this architecture is to divide the big dataset into several small ones, and run the analysis on different servers. The final output will be recompiled and returned to us. I think this idea is really helpful in my learning as a data analyst. When I need to handle massive data, I can reduce the dataset and do analysis. \n\n\n\n\n\nMapReduce architecture. Source: Sidhu, Pebesma, and Câmara, 2018\n\n\n\n\nLike the video about machine learning at the end of the lecture, I think machine learning will be an efficient tool that can help me to handle large image datasets. I can use the datasets to build a machine-learning model, and the model can predict the component or characteristics in the images. Also, the paper I mentioned in week 4 also uses the machine learning method to discover potential planting sites. So I think this can help me to figure out the classification problems in remote sensing.\n\n\n\n\nErmida, Sofia L., Patrícia Soares, Vasco Mantas, Frank-M. Göttsche, and Isabel F. Trigo. 2020. “Google Earth Engine Open-Source Code for Land Surface Temperature Estimation from the Landsat Series.” Remote Sensing 12 (9): 1471. https://doi.org/10.3390/rs12091471.\n\n\nSidhu, Nanki, Edzer Pebesma, and Gilberto Câmara. 2018a. “Using Google Earth Engine to Detect Land Cover Change: Singapore as a Use Case.” European Journal of Remote Sensing 51 (1): 486–500. https://doi.org/10.1080/22797254.2018.1451782.\n\n\n———. 2018b. “Using Google Earth Engine to Detect Land Cover Change: Singapore as a Use Case.” European Journal of Remote Sensing 51 (1): 486–500. https://doi.org/10.1080/22797254.2018.1451782.\n\n\n———. 2018c. “Using Google Earth Engine to Detect Land Cover Change: Singapore as a Use Case.” European Journal of Remote Sensing 51 (1): 486–500. https://doi.org/10.1080/22797254.2018.1451782."
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "6  Week6 Classification I",
    "section": "6.1 Summary",
    "text": "6.1 Summary\n\n6.1.1 Mind map\n\n\n\n\n\nMind map. Source: Yanbo\n\n\n\n\n\n\n6.1.2 Applications of classified data\nMonitoring forests —– illegal logging\nThe illegal logging case is very interesting, because illegal loggers use technical ways to avoid the monitoring of forests. When researchers classify the imagery data of forests, small logging areas are ignored because the resolution of imagery (250*250m) is larger than the size of logging areas. These illegal logging areas are hidden in the picture and not able to be detected. Therefore, the high resolution data is important in the classification problems.\n\n\n\n\n\nIllegal logging patch. Source: Image courtesy of DEMA-AP\n\n\n\n\n\n\n6.1.3 Machine learning methods\n\n6.1.3.1 Decision tree (CART)\nIt can apply in both classification and regression problem, which is a binary tree. CART uses the Gini coefficient to make splits, and it represents the model’s impurity. The smaller the Gini coefficient indicates the lower the impurity, and the better outputs.\n\n\n\n\n\nGini Impurity formula. Source: Huy Bui\n\n\n\n\nClassification\nThe predicted values are classified into two or more, and they are discrete.\nThe example of decision tree:\nShould I take CASA0023?\n\n\n\n\n\nDecision tree. Source: Yanbo\n\n\n\n\nRegression\nThe predicted values are continuous, like housing price, GCSE scores.\n\n\n\n\n\nDecision tree regression. Source: scikit-learn\n\n\n\n\nOverfitting\nWhen the max depth of tree is high (red line in previous figure), the tree learn too fine details, so it casues overfitting problems.\nTwo ways to avoid overfitting:\n\nlimit how trees grow (eg. a minimum number of pixels in a leaf, 20 is often used)\nWeakest link pruning (with tree score)\nTree score = SSR (The sum of squared residuals)+ tree penalty (alpha) * T (number of leaves)\n\nHow to do in code?\n\nlimit number of leaves in each tree\nchange Alpha\n\nHyperparameter-tuning\nIt is a process that finds the best parameter (Alpha in Decision Tree) of model in machine learning.\n\n\n\n\n\nHyperparameter tuning Worlflow. Source: Yanbo\n\n\n\n\n\n\n6.1.3.2 Random forest\nIt is made up of many decision trees. It reduces the risk of overfitting because it make decision tree from random number of variables (never all of them), and take a random subset of variables again.\n\n\n\n\n\nDecision tree vs Random forest. Source: Rosaria Silipo\n\n\n\n\nBootstrapping is re-sampling and replacing data to make a decision.\n\n\n\n\n\nRandom forest classifier on a dataset. Source: Siddharth Misra, Hao Li\n\n\n\n\n\n\n6.1.3.3 Support Vector Machine (SVM)\nThis algorithm is to find a hyperplane in a N-dimensional space that can classify all data. It introduces in the framework of structural risk minimization (SRM).\n\n\n\n\n\nSVM. Source: javaTpoint\n\n\n\n\nSVM in 3D uses a plane instead of a line when there are more than two datasets.\n\n\n\n\n\nHyperplanes in 2D and 3D. Source: Rohith Gandhi\n\n\n\n\nHyperparameter-tuning in SVM\n\nType of kernel (rbf, poly, linear, sigmoid)\nC controls training data and decision boundary maximisation plus margin errors\n\n\n\n\n\n\nC = 1000, 50, 5. Source: Dishaa Agarwal\n\n\n\n\n\nGamma (or Sigma) control radius for classified points\n\n\n\n\n\n\nGamma = 0, 10, 100. Source: Sunil Ray\n\n\n\n\n\n\n\n6.1.4 How image classification works?\nImage classification turn every pixel in the image into one pre-defined categorical classification. The following picture shows how computer see in image . In remote sensing, if the pixel values are similar, and they probably are the same classes. The previous machine learning methods are used to classify these pixel values.\n\n\n\n\n\nSource: Thilo Huellmann\n\n\n\n\n\n\n\n\n\nSupervised vs Unsupervised procedures. Source: Yanbo\n\n\n\n\n\n\n6.1.5 Classification on GEE\nMy case in Hong Kong code link: https://code.earthengine.google.com/0158a598d6dd7961dcfeacd9854ebff7\n\n\n\n\n\nClassification workflow in GEE. Source: Yanbo\n\n\n\n\nThe left picture is the output from CART and it doesn’t split training and testing data. The right picture is the output from Random Forest, and the classifier was trained with 70% training pixels, and the training accuracy is 0.9980750721847931, the validation accuracy is 0.9956616052060737. The left output classify more forest areas than the right output.\nIn my case, class 1 is water, class 2 is forest, class 3 is urban.\n\n\n\n\n\nCART output vs RF output. Source: Yanbo"
  },
  {
    "objectID": "week6.html#application",
    "href": "week6.html#application",
    "title": "6  Week6 Classification I",
    "section": "6.2 Application",
    "text": "6.2 Application\nClassification in GEE is one of the common application. When we are doing some of classification problems, what types of data and what methods for classification we are using are essential because it can directly affect the accuracy of our final output. This application part tries to review some studies that provide some information about data selection and method selection when doing classification tasks.\n\n6.2.1 Case1: Land Cover Classification using Google Earth Engine and Random Forest Classifier—The Role of Image Composition\nIn our lecture, we learned median, mean and other method to reduce the data volume, but we don’t know how it affect the overall accuracy in the classification. This study explores the overall accuracy between time series data and temporal aggregation data in land cover classification. Phan, Kuch, and Lehnert (2020) found the time-series data has the highest overall accuracy (dataset 7 and 8), but the temporal aggregation data (dataset 2) also have an almost equally high overall accuracy in classification on the GEE. Therefore, they suggested we need to prioritize using temporal aggregation data (like median composite method) because the data volume is low, and it also can reduce the influence of cloud and snow in classification.\n\n\n\n\n\nUser’s (UA), producer’s (PA) and overall (OA) accuracies. Source: Phan, Kuch, and Lehnert, 2020\n\n\n\n\nData\nThe dataset 1 to 6 are the median composite of image collection, and dataset 7 to 8 are time series data.\n\n\n\n\n\nThe composition of the eight datasets. Source: Phan, Kuch, and Lehnert, 2020\n\n\n\n\nMethod\nThe flow of method is similar to the practical we did. In this case, I noticed that they used very high resolution images, field work data, and other data in their training and testing data. This supports them to have a better classifier.\n\n\n\n\n\nWorkflow of analysis. Source: Phan, Kuch, and Lehnert, 2020\n\n\n\n\nOutput\n\n\n\n\n\nThe final output of eight datasets. Source: Phan, Kuch, and Lehnert, 2020\n\n\n\n\n\n\n6.2.2 Case2: Analysis of Land Use and Land Cover Using Machine Learning Algorithms on Google Earth Engine for Munneru River Basin, India\nThis paper explore three machine learning algorithms including Random Forest (RF), Classification and Regression Tree (CART), and Support Vector Machine (SVM). Loukika, Keesara, and Sridhar (2021a) compared performance of three algorithms in the Land cover and land use classification problem. They found all of them have a high performance, but RF is outperformed. In addition, the dataset also have influence on the final performance. The Sentinel-2 dataset has a better performance than Landsat-8 dataset because Sentinel-2 (10m) has a higher resolution than Landsat-8 (30m), and Sentinel-2 dataset has red-edge bands. Therefore, they also found the band combinations and resolution will affect the accuracy of classification.\nData\n\n\n\n\n\n\n\n\nYear\nTotal number of images used in Landsat-8\nTotal number of images used in Sentinel-2\n\n\n\n\n2016\n10\n23\n\n\n2018\n15\n44\n\n\n2020\n14\n36\n\n\n\n\n\n\n\n\nLandsat-8 and Sentinel-2 band information. Source: Loukika, Keesara, and Sridhar, 2021\n\n\n\n\nMethod\n\n\n\n\n\nWorkflow of method. Source: Loukika, Keesara, and Sridhar, 2021\n\n\n\n\nOutput\n\n\n\n\n\nLandsat-8 output. Source: Loukika, Keesara, and Sridhar, 2021\n\n\n\n\n\n\n\n\n\nSentinel-2 output. Source: Loukika, Keesara, and Sridhar, 2021\n\n\n\n\n\n\n\n\n\nKappa coefficient and overall accuracy of Landsat-8 and Sentinel-2. Source: Loukika, Keesara, and Sridhar, 2021\n\n\n\n\nIn the above table, all overall accuracy is relatively high in classification, so there are probably potential overfitting problems. Loukika, Keesara, and Sridhar (2021b) discussed some vegetation was misclassified as forest, and some parts of river was misclassified as barren or built-up. These misclassification probably is one of reason that causes overfitting, and it should be always notified in the classification."
  },
  {
    "objectID": "week6.html#reflection",
    "href": "week6.html#reflection",
    "title": "6  Week6 Classification I",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nHyperparameter-tuning is really useful in training a classifier because I have used this concept in training a regression model. It provides me a better R2 in my housing prediction case. Although the content and purpose are different, the method is similar. Both of them are tries to find the best parameter to build the model. For example, finding how many trees in RF can be the best classifier.\nIn the practical, my training accuracy and validation accuracy is so high, and it has overfitting problems. I think there are two reasons, the number of classes is small. Only three classes in my study area, and many area are misclassified into these three classes, in particular, forest and urban. The other reason probably is because I don’t pick various training data. Some of my training data I draw only have the short distance among them, this may cause they has the higher similarity or spatial autocorrelation. Therefore, I think I need to learn more methods that can help me avoid overfitting problems and selecting better training data.\nThe evaluation methods of classification was not mentioned in this week content, and this is also one of important component in the machine learning. In the application, two papers mentions user’s accuracy, producers’ accuracy, overall accuracy, and Kappa coefficient. These evaluation metrics that I need to explore in the following weeks.\nThe median composite method has been mentioned many times in previous weeks, but I don’t consider how it will affect the performance of classifier. In application case1, the performance of this method has been examined. I think I can use median composite method in my future analysis.\nAs for data selection, I think I need to find the better resolution data with a good combination of bands, which may provide me a better classification. As for method selection, I think it may depend on my research purposes and objectives. Like Andy mentioned in the class, high accuracy doesn’t always mean the good output. In my understanding, RF, CART, and SVM are machine learning methods in the remote sensing, but the deep learning nowadays are also highly applied into many fields. In the future, I want to explore how deep learning method, like CNN, RNN applied into remote sensing problems.\n\n\n\n\nLoukika, Kotapati Narayana, Venkata Reddy Keesara, and Venkataramana Sridhar. 2021a. “Analysis of Land Use and Land Cover Using Machine Learning Algorithms on Google Earth Engine for Munneru River Basin, India.” Sustainability 13 (24): 13758. https://doi.org/10.3390/su132413758.\n\n\n———. 2021b. “Analysis of Land Use and Land Cover Using Machine Learning Algorithms on Google Earth Engine for Munneru River Basin, India.” Sustainability 13 (24): 13758. https://doi.org/10.3390/su132413758.\n\n\nPhan, Thanh Noi, Verena Kuch, and Lukas W. Lehnert. 2020. “Land Cover Classification Using Google Earth Engine and Random Forest ClassifierThe Role of Image Composition.” Remote Sensing 12 (15): 2411. https://doi.org/10.3390/rs12152411."
  },
  {
    "objectID": "week7.html#summary",
    "href": "week7.html#summary",
    "title": "7  Week7 Classification II",
    "section": "7.1 Summary",
    "text": "7.1 Summary\n\n7.1.1 Mind map\n\n\n\n\n\nMind map. Source: Yanbo\n\n\n\n\n\n\n7.1.2 Classification Approaches\n\n7.1.2.1 Object based image analysis\nIn classification, a pixel can’t represent an object, and an object normally is made up of many pixels. There are many methods in object based image analysis. Superpixels consider the similarity of pixels and homogeneity of the pixels, and Simple Linear Iterative Clustering (SLIC) is one of most common method to generate superpixels. For example, the centroid of objects moves iteratively, and the images become more object-based images.\n\n\n\n\n\nSupercells. Source: Nowosad 2021\n\n\n\n\nBears in right picture are objected based, and similar pixels are clustered as superpixels.\n\n\n\n\n\nSupercells. Source: Darshite Jain\n\n\n\n\nOther algorithms\n\nmulti-resolution segmentation in eCognition Definiens Developer\n\n\n\n7.1.2.2 Sub pixel analysis\nIt was also called Spectral Mixture Analysis, Linear spectral unmixing. It proivdes the details in every single pixel, and it estimates the fractions that made up of this pixel. For example, it shows how many percent of urban area, and how many percent of vegetation, and how many percent of water.\n\n\n\n\n\nSource: Machado and Small 2013\n\n\n\n\nIn terms of how it works, the linear sum of endmembers weighted by associated endmember fraction represents the reflectance in each bands. For example, water is 13 in Band 3, and this is a endmember. Then, the percentage of different objects can be calculated based on endmembers.\n\n\n\n\n\nSource: Andrew 2023\n\n\n\n\n\n\n\n7.1.3 Accuracy assessment\nThe evaluation is essential part in the classification, and different evaluation methods may give us different performances of our classification. The terms in remote sensing are different in machine learning, and we need to balance the accuracy between producer accuracy and user accuracy because it’ hard to get the best in both of them.\nProducer, user and overall accuracy\n\n\n\nRemote Sensing\n\nMachine Learning\n\n\n\n\nProducer accuracy (PA)\nTP/TP+FN\nRecall\n\n\nUser accuracy (UA)\nTP/TP+FP\nPrecision\n\n\nOverall accuracy (OA)\nTP+TN/TP+FP+FN+TN\nOverall accuracy\n\n\n\n\n\n\n\n\nConfusion Matrix Source: Rohit 2023\n\n\n\n\nErrors\nprovide performance of our classification. The following matrix shows error matrix in remote sensing.\n\nError of omission = 100 - PA\nOpen land = 42/180 = 24%\nOpen land producer = 138/180= 76%\nError of commission = 100 - UA\nOpen land = 68/206 = 33%\nOpen land user = 138/206= 67%\n\n\n\n\n\n\nError Matrix Source: Chegg\n\n\n\n\nKappa\nexpress the accuracy of an image compared to the results by chance. However, it has two limitations, one is hard to define a good value, and the other is Kappa values have different levels of accuracy.\nF1 score\ncombines producer accuracy and user accuracy, range from 0 to 1, and 1 is the best performance. It also has two limitations, it doesn’t consider the true negative, and it considers user accuracy and producer are equally important.\n\n\n\n\n\n\n\n\n\nReceiver Operating Characteristic Curve (ROC Curve)\nis a graph showing the performance of classifier at all classification thresholds.\nAUC (area under the ROC Curve) stands for all area under the entire ROC Curve.\n\n\n\n\n\nROC and AUC: Jared 2022\n\n\n\n\n\n\n7.1.4 Test and train data\nCross-validation\na resampling method that uses different portions of the data to test and train a classifier on different iterations. The accuracy is the average of all classifers.\n\n\n\n\n\nCross validation: scikit learn\n\n\n\n\nSpatial cross validation\nis the cross validation that consider spatial dependence. Spatial autocorrelation are happens between training and testing data. Spatial cross validation spatially partitioning the folded data, and stops training and testing data being near each other. For example, if there are two seprate forest in the image, and the training data are from the first forest, and the testing data are from second forest.\n\n\n\n\n\nCross validation vs Spatial cross validation: Chiara 2021\n\n\n\n\n\n\n7.1.5 Applications of classification approaches on GEE\nThe approaches including subpixel, superpixel, and object-based have been introduced in the previous part, and here I used GEE to do a classification for Tianjian, China on GEE. The key steps were summarized in the following workflow.\nMy code link is https://code.earthengine.google.com/4eaa3862a6f9c091e16da1f2c8b82ff2\n\n\n\n\n\nWorkflow. Source: Yanbo\n\n\n\n\nThe following pictures are my results. In the super pixel, the pixels were clustered as a bigger pixel. The differences among small pixels were removed, and they become a bigger pixel. In object-based, if there are more higher resolution data, the results will be more better than current one.\n\n\n\n\n\nResults of practical. Source: Yanbo\n\n\n\n\nIn subpixel, the classified results are based on the percent of each pixel. If the pixel is greater than 0.5, then give this pixel a value, like 1 refers to high_urban.\n\n\n\n\n\nPercent of each endmember per pixel. Source: Yanbo\n\n\n\n\n\n\n7.1.6 Useful pre-classified data resource\nMany pre-classified data we can use in our future analysis, and the Dynamic World also combine deep learning approaches in their classification.\n\nGlobeLand30 - 30m for 2000, 2010 and 2020: http://www.globallandcover.com/home_en.html?type=data\nEuropean Space Agency’s (ESA) Climate Change Initiative (CCI) annual global land cover (300 m) (1992-2015): https://climate.esa.int/en/projects/land-cover/data/\nDynamic World - near real time 10m: https://www.dynamicworld.app/explore/\nMODIS: https://modis.gsfc.nasa.gov/data/dataprod/mod12.php\nGoogle building data: https://sites.research.google/open-buildings/\n\nSource: Andrew 2023"
  },
  {
    "objectID": "week7.html#application",
    "href": "week7.html#application",
    "title": "7  Week7 Classification II",
    "section": "7.2 Application",
    "text": "7.2 Application"
  },
  {
    "objectID": "week7.html#reflection",
    "href": "week7.html#reflection",
    "title": "7  Week7 Classification II",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection"
  },
  {
    "objectID": "week8.html#summary",
    "href": "week8.html#summary",
    "title": "8  Week8 Temperature and policy",
    "section": "8.1 Summary",
    "text": "8.1 Summary\n\n8.1.1 Mind map\n\n\n\n\n\nMind map. Source: Yanbo\n\n\n\n\nThe mind map shows basic structure for this week lecture, and the key point is recognizing the gap among global, local, metropolitan, and involving data analysis. The detailed and data-driven interventions will be the great measures to fill the current policy gap in many urban problems, like urban heat island, pollution and so on.\n\n\n8.1.2 Temperature Problem Definition\n\n8.1.2.1 Urban Heat Island (UHI)\nWhat is UHI?\nThe urban heat island refers to the city center has higher temperature than the suburb and rural area.\n\n\n\n\n\nUrban heat island. Source: Saurab 2017\n\n\n\n\nWhy UHI happens?\nMany factors causes UHI, like reduced natural landscape,urban construction materials, heat from human activities, and others.\n\n\n\nUHI factors\nWhy they increase temperature\n\n\n\n\nMore dark surfaces\nAbsorb and retain more heat\n\n\nLess vegetation\nLess cooling in the environment\n\n\nHuman activities\nIndustrial production generate more heat\n\n\n\nUHI costs\nUHI has many negative effects on our society.\n\n\n\n\n\n\n\nAspects\nCosts\n\n\n\n\nSocial\nHigh mortality in urban area\n\n\nEnvironmental\nIncreased energy usage (more fossil fuels and pollution)\n\n\nEconomic\nGDP loss\n\n\n\n\n\n\n8.1.3 Policy solutions\nPolicy can provide cities a good direction that help them to mitigate UHI effects, and the policy solutions basically can be described at the following three levels. However, all of this policies solutions have limitations. They doesn’t consider the feasibility and the specific implementations for cities.\n\n8.1.3.1 Global\nSome global policies are related to the mitigation of UHI, but there don’t have specific guidance for implementation of cities, and they are just big goals and targets.\nNew Urban Agenda\n\nPoint 37 We commit ourselves to promoting safe, inclusive, accessible, green and quality public spaces, including streets, sidewalks and cycling lanes, squares, waterfront areas, gardens and parks, that are multifunctional areas for social interaction and inclusion, human health and well-being.\n\n\nPoint 79 We commit ourselves to promoting international, national, subnational and local climate action, including climate change adaptation and mitigation, and to supporting the efforts of cities and human settlements, their inhabitants and all local stakeholders as important implementers.\n\nSustainable Development Goals (SDG)\n\nGoal 11 Make cities and human settlements inclusive, safe, resilient and sustainable.\n\n\n\n8.1.3.2 Local\nBeat the heat handbook\nThis hand book from United Nations is the first major document that has specific integration into policy. Although it has some specific interventions in the local level, the handbook is so much information for local planners and managers. Also, interventions don’t contain specific procedures and steps for city managers, and solutions to reduce the urban temperature.\n\n\n\n\n\nSource: Beating the Heat: A Sustainable Cooling Handbook for Cities\n\n\n\n\n\nSuperblock in Barcelona\nThis right picture shows a superblock. In the superblock, cars are restricted or banned, this will create more spaces for walking and bicycling. Outside the superblock, the traffic speed is limited with a maximum (50km/h). This will provide more green spaces for residents and encourage people to walk and bicycle, and reduce heat, noise and pollution. The problem for this plan may cause less business because of less car, and less community support.\n\n\n\n\n\nSource: Patrick Mark 2019\n\n\n\n\nThe video provides a really good introduction about superblock, and I think it is a nice idea in my future geographic study.\n\nMedellín Green Corridors\nThis plan intends to build 36 corridors along 18 roads and waterways in the city, this will reduce 4 degrees for their temperature.\n\n\n\n\n\nGreen corridor. Source: Lberdrola\n\n\n\n\nSydney’s western suburbs\nThis plan assesses the current state and the future of UHI in Western Sydney, which predicts the increasing severity and frequency of heat waves, and effects on citizens.\n\n\n8.1.3.3 Metropolitan\nSome of metropolitan plans have a temperature reduction activities, and they can be improved in the future. There are some of potential useful ideas which may combine in the temperature reduction.\n\nuse reflective materials (like roofs, parking lots)\nengage community members\nbetter accessibility to green spaces\nbetter planned community avoid disparities\n\nSeattle’s policy\nThe policy in Seattle requires all the citizens reach the minimum score established by the zoning your property, and this engages citizens to indirectly reduce the UHI. The limitation of this are no requirments about locations of green vegetation, which may have no influence on temperature reduction.\n\n\n\n\n\nSource: Seattle.gov\n\n\n\n\nFremantle’s Urban Forest Plan\nThis plan go through more details because it uses data to analyze where to increase the green spaces. In terms of limitation, it only include one month data, which may biased. Also, the analysing scale (the block) they used are too big. For example, the temperature in block may be various, but in this case the temperature is same in each block.\n\n\n\n\n\nSource: City of Fremantle\n\n\n\n\n\n\n\n8.1.4 Approaching projects\n\n\n\n\n\nApproaching steps. Source: Yanbo\n\n\n\n\n\n\n8.1.5 Temperature applications on GEE\nThe export the temperture shapefile on GEE is useful for doing future researches. In this practical, I used both Landsat and MODIS data to generate LST data for Tianjin, China. The MODIS data is better because it can scan twice a day for the same place. The detailed steps were summarzied in the workflow.\nMy code link: https://code.earthengine.google.com/6492a6b735deeb5904360326cfde723e\n\n\n\n\n\nApproaching steps. Source: Yanbo\n\n\n\n\nThe LST from Landsat was displayed using the same palette with MODIS, so it seems not really good, and also there is a clear dividing line on the map. I guess this is because the LST data were extracted from two separated Landsat images.\n\n\n\n\n\nlandsat LST vs MODIS LST. Source: Yanbo\n\n\n\n\nThe spatial unit temperature were calculated on GEE, and then exported to shapefile using R to analyze percentile rank. The process of this step is easier in R rather than using GEE.\n\n\n\n\n\nSpatial unit temperature from R. Source: Yanbo\n\n\n\n\n\n\n\n\n\nSpatial unit temperature from GEE. Source: Yanbo\n\n\n\n\nThe time series chart was generated on GEE, which is quite easy.\n\n\n\n\n\nTime series chart. Source: Yanbo"
  },
  {
    "objectID": "week8.html#application",
    "href": "week8.html#application",
    "title": "8  Week8 Temperature and policy",
    "section": "8.2 Application",
    "text": "8.2 Application"
  },
  {
    "objectID": "week8.html#reflection",
    "href": "week8.html#reflection",
    "title": "8  Week8 Temperature and policy",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection"
  },
  {
    "objectID": "week9.html#summary",
    "href": "week9.html#summary",
    "title": "9  Week9 SAR",
    "section": "9.1 Summary",
    "text": "9.1 Summary"
  },
  {
    "objectID": "week9.html#application",
    "href": "week9.html#application",
    "title": "9  Week9 SAR",
    "section": "9.2 Application",
    "text": "9.2 Application"
  },
  {
    "objectID": "week9.html#reflection",
    "href": "week9.html#reflection",
    "title": "9  Week9 SAR",
    "section": "9.3 Reflection",
    "text": "9.3 Reflection"
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "5  Quarto Computations",
    "section": "",
    "text": "6 Week5 An introduction to Google Earth Engine"
  },
  {
    "objectID": "index.html#ackownledgement",
    "href": "index.html#ackownledgement",
    "title": "Learning Diary for CASA0023",
    "section": "Ackownledgement",
    "text": "Ackownledgement\nI would like to thank Dr. Andrew MacLachlan for helping with this book."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Learning Diary for CASA0023",
    "section": "About me",
    "text": "About me\nI’m Yanbo Liu from Zhangjiakou, Hebei Province, China. I currently study in Social and Geographic Data Science program at University College London (UCL). I finished my undergraduate in Urban Forestry at the University of British Columbia (UBC). I hope I will become a geographic data analyst, and I’m interested in spatial data analysis, machine learning, and deep learning. I think data is future!"
  },
  {
    "objectID": "index.html#about-this-book",
    "href": "index.html#about-this-book",
    "title": "Learning Diary for CASA0023",
    "section": "About this book",
    "text": "About this book\nThis book was written in Spring 2023 at UCL master, and it was part of my assessment for CASA0023 (Remote Sensing Cities and Environments). It was edited by using Quarto Book, and all codes were opensource on my Github. The contents cover remote sensing principles, applications, and its analysis in R and Google Earth Engine. If you are interested in remote sensing or spatial data analysis, I think this book would be helpful."
  }
]